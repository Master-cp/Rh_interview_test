import boto3
from pathlib import Path
import tempfile 
import streamlit as st
from groq import Groq
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.embeddings import HuggingFaceEmbeddings 
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from gtts import gTTS
from io import BytesIO
import speech_recognition as sr
import os
import time
import json
import numpy as np
from audiorecorder import audiorecorder


# Initialisation du client Polly
polly_client = boto3.client('polly',
                           aws_access_key_id=st.secrets["AWS_ACCESS_KEY_ID"],
                           aws_secret_access_key=st.secrets["AWS_SECRET_ACCESS_KEY"],
                           region_name='us-east-1')

# Configuration Groq
client = Groq(api_key=st.secrets["GROQ_API_KEY"])   

# ------------------------------------------------------------
# CLASSES ET FONCTIONS AM√âLIOR√âES
# ------------------------------------------------------------
class RecruitingAgent:
    def __init__(self):
        self.phase = "initial"
        self.history = []
        self.vector_db = None
        self.job_description = ""
        self.cv_text = ""
        self.evaluations = []
        self.job_summary = {}
        self.candidate_profile = {
            "competences_identifiees": [],
            "experiences_cles": [],
            "points_forts": [],
            "points_faibles": [],
            "motivations": []
        }
        self.question_count = 0
        self.max_questions = 6
        
    def analyze_job_description(self, job_desc):
        """Analyse et r√©sume la description de poste"""
        prompt = f"""
        [DESCRIPTION DE POSTE √Ä ANALYSER]
        {job_desc}

        [INSTRUCTIONS]
        En tant qu'expert RH, analysez cette offre d'emploi et :
        1. Extrayez un titre concis (max 5 mots)
        2. Listez les 3 comp√©tences techniques principales
        3. Listez les 3 qualit√©s comportementales cl√©s
        4. Identifiez le niveau d'exp√©rience requis
        5. Extrayez 2 indicateurs de performance cl√©s
        6. R√©sumez en 2 phrases les responsabilit√©s principales

        Formattez la r√©ponse en JSON avec ces cl√©s :
        - "titre"
        - "competences_techniques"
        - "qualites_comportementales"
        - "niveau_experience"
        - "indicateurs_performance"
        - "responsabilites_principales"
        """
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            response_format={"type": "json_object"}
        )
        
        self.job_summary = eval(response.choices[0].message.content)
        return self.job_summary
    
    def initialize_interview(self, cv_file, job_description):
        """Initialise l'entretien avec analyse pr√©alable"""
        self.job_description = job_description
        self.job_summary = self.analyze_job_description(job_description)
        
        # Traitement des documents
        self.cv_text, self.vector_db = self.process_documents(cv_file, job_description)
        self.phase = "interview"
        self.question_count = 0
        
        # Message d'introduction personnalis√©
        intro_message = (
            f"**Entretien pour le poste : {self.job_summary['titre']}**\n\n"
            f"**Comp√©tences recherch√©es :** {', '.join(self.job_summary['competences_techniques'])}\n"
            f"**Profil attendu :** {self.job_summary['niveau_experience']} avec {', '.join(self.job_summary['qualites_comportementales'])}\n\n"
            "Commen√ßons par votre pr√©sentation. Pourriez-vous vous d√©crire en 2 minutes "
            "en mettant l'accent sur votre ad√©quation avec ce poste ?"
        )
        
        self.add_system_message(intro_message)
        self.question_count += 1
        
    def process_documents(self, cv_file, job_desc):
        """Traite les documents et extrait les informations cl√©s"""
        with tempfile.TemporaryDirectory() as temp_dir:
            cv_path = os.path.join(temp_dir, cv_file.name)
            with open(cv_path, "wb") as f:
                f.write(cv_file.getvalue())
            
            loader = PyPDFLoader(cv_path)
            cv_data = loader.load()
        
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=300)
        cv_full_text = ''.join([d.page_content for d in cv_data])
        combined_text = f"CV DU CANDIDAT:\n{cv_full_text}\n\nDESCRIPTION DE POSTE:\n{job_desc}"
        
        return cv_full_text, FAISS.from_texts(
            texts=text_splitter.split_text(combined_text),
            embedding=HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
        )

    def extract_candidate_insights(self, user_response):
        """Extrait des insights du candidat de sa r√©ponse"""
        prompt = f"""
        [R√âPONSE DU CANDIDAT]
        {user_response}

        [INSTRUCTIONS]
        Extrayez les informations suivantes de la r√©ponse :
        1. Comp√©tences techniques mentionn√©es
        2. Exp√©riences professionnelles significatives
        3. Points forts d√©montr√©s
        4. Points faibles potentiels
        5. Motivations exprim√©es

        R√©pondez en JSON avec ces cl√©s :
        - "competences_identifiees": liste
        - "experiences_cles": liste
        - "points_forts": liste
        - "points_faibles": liste
        - "motivations": liste
        """
        
        try:
            response = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.4,
                response_format={"type": "json_object"}
            )
            
            insights = eval(response.choices[0].message.content)
            
            # Mise √† jour du profil candidat
            for key in self.candidate_profile.keys():
                if key in insights and insights[key]:
                    self.candidate_profile[key].extend(insights[key])
            
            return insights
            
        except Exception as e:
            print(f"Erreur extraction insights: {e}")
            return {}
    
    def check_candidate_cannot_continue(self, user_response):
        """V√©rifie si le candidat indique ne pas pouvoir suivre la rencontre"""
        stop_phrases = [
            "je ne peux pas continuer",
            "je ne peux pas suivre",
            "je souhaite arr√™ter",
            "stop l'entretien",
            "arr√™ter l'entretien",
            "terminer maintenant",
            "je pr√©f√®re arr√™ter",
            "je veux arr√™ter",
            "pas possible de continuer",
            "impossible de poursuivre"
        ]
        
        user_response_lower = user_response.lower()
        return any(phrase in user_response_lower for phrase in stop_phrases)
    
    def generate_contextual_question(self, user_response):
        """G√©n√®re des questions contextuelles bas√©es sur l'historique"""
        # V√©rifier si le maximum de questions est atteint
        if self.question_count >= self.max_questions:
            thank_you_message = (
                "Merci beaucoup pour vos r√©ponses. Nous avons maintenant suffisamment "
                "d'√©l√©ments pour √©valuer votre candidature. "
                "Passons √† l'√©valuation finale de votre profil."
            )
            return thank_you_message
        
        # Extraction des insights de la r√©ponse
        insights = self.extract_candidate_insights(user_response)
        
        prompt = f"""
        [CONTEXTE DE L'ENTRETIEN]

        POSTE RECHERCH√â:
        - Titre: {self.job_summary['titre']}
        - Comp√©tences techniques requises: {self.job_summary['competences_techniques']}
        - Qualit√©s comportementales: {self.job_summary['qualites_comportementales']}
        - Responsabilit√©s: {self.job_summary['responsabilites_principales']}

        PROFIL DU CANDIDAT (extrait des r√©ponses pr√©c√©dentes):
        - Comp√©tences identifi√©es: {self.candidate_profile['competences_identifiees'][-3:] if self.candidate_profile['competences_identifiees'] else 'Aucune identifi√©e'}
        - Exp√©riences cl√©s: {self.candidate_profile['experiences_cles'][-2:] if self.candidate_profile['experiences_cles'] else 'Aucune mentionn√©e'}
        - Points forts: {self.candidate_profile['points_forts'][-2:] if self.candidate_profile['points_forts'] else 'Non sp√©cifi√©s'}

        DERNI√àRE R√âPONSE DU CANDIDAT:
        {user_response[:500]}

        HISTORIQUE DE L'ENTRETIEN (derni√®res interactions):
        {str(self.history[-3:]) if len(self.history) > 3 else 'D√©but de conversation'}

        [INSTRUCTIONS]
        En tant que recruteur expert, posez UNE seule question qui:
        1. S'appuie sur la derni√®re r√©ponse du candidat
        2. Explore les comp√©tences requises pour le poste
        3. V√©rifie l'ad√©quation avec les responsabilit√©s du poste
        4. Maximum 70 mots
        5. En fran√ßais, naturel et conversationnel

        La question doit cr√©er un continuum logique avec l'√©change pr√©c√©dent.
        """
        
        messages = [
            {"role": "system", "content": "Vous √™tes un recruteur technique expert, posez des questions pertinentes et naturelles."},
            *[{"role": "assistant" if role == "system" else "user", "content": msg} 
              for role, msg in self.history[-4:]],  # Garder les 4 derniers √©changes
            {"role": "user", "content": prompt}
        ]
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            temperature=0.7,
            max_tokens=100
        )
        
        self.question_count += 1
        return response.choices[0].message.content.strip()
    
    def add_system_message(self, message):
        """Ajoute un message syst√®me avec historique"""
        self.history.append(("system", message))
        st.session_state.messages.append({
            "role": "assistant",
            "content": message
        })

    def evaluate_response(self, user_response):
        """√âvalue la r√©ponse du candidat de mani√®re contextuelle"""
        prompt = f"""
        [CONTEXTE D'√âVALUATION]

        EXIGENCES DU POSTE:
        - Comp√©tences: {self.job_summary['competences_techniques']}
        - Qualit√©s: {self.job_summary['qualites_comportementales']}
        - Niveau: {self.job_summary['niveau_experience']}

        HISTORIQUE R√âCENT:
        {str(self.history[-2:]) if len(self.history) >= 2 else 'Premi√®re question'}

        R√âPONSE √Ä √âVALUER:
        {user_response}

        [CRIT√àRES D'√âVALUATION]
        1. Pertinence (1-5) : Ad√©quation avec la question pos√©e
        2. D√©tail technique (1-5) : Pr√©cision des informations
        3. Ad√©quation poste (1-5) : Lien avec les exigences du poste
        4. Progression (1-5) : Am√©lioration par rapport aux r√©ponses pr√©c√©dentes

        Fournissez un feedback constructif en 2-3 phrases maximum.
        """
        
        evaluation = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4
        ).choices[0].message.content
        
        self.evaluations.append({
            "reponse": user_response[:200],
            "evaluation": evaluation,
            "timestamp": time.time()
        })
        
        return evaluation

    def evaluate_performance(self):
        """G√©n√®re un rapport final complet"""
        prompt = f"""
        [SYNTH√àSE FINALE]

        POSTE: {self.job_summary['titre']}
        COMP√âTENCES REQUISES: {self.job_summary['competences_techniques']}

        PROFIL CANDIDAT IDENTIFI√â:
        - Comp√©tences: {self.candidate_profile['competences_identifiees']}
        - Exp√©riences: {self.candidate_profile['experiences_cles']}
        - Points forts: {self.candidate_profile['points_forts']}
        - Motivations: {self.candidate_profile['motivations']}

        HISTORIQUE COMPLET: {json.dumps(self.history, ensure_ascii=False)}
        √âVALUATIONS: {json.dumps(self.evaluations, ensure_ascii=False)}

        [INSTRUCTIONS]
        R√©digez un rapport d√©taill√© en fran√ßais avec:
        1. Score global sur 10 avec justification
        2. Points forts align√©s avec le poste
        3. Points d'am√©lioration critiques
        4. Recommandations concr√®tes pour le candidat
        5. Ad√©quation finale avec le poste (Fort/Moyen/Faible)

        Structurez avec des sections claires et soyez constructif.
        """
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        return response.choices[0].message.content

# ------------------------------------------------------------
# FONCTIONS AUDIO AM√âLIOR√âES
# ------------------------------------------------------------
def text_to_speech(text):
    """Synth√®se vocale avec AWS Polly TTS (voix fran√ßaise)"""
    try:
        # Cr√©ation d'un fichier temporaire pour l'audio
        speech_file_path = Path(tempfile.gettempdir()) / "speech.mp3"
        
        # Appel AWS Polly API TTS
        response = polly_client.synthesize_speech(
            Engine='generative',
            OutputFormat='mp3',
            Text=text,
            VoiceId='Liam',
            TextType='text'
        )
        
        # Sauvegarde du fichier audio
        if 'AudioStream' in response:
            with open(speech_file_path, 'wb') as file:
                file.write(response['AudioStream'].read())
        
        return str(speech_file_path)
        
    except Exception as e:
        print(f"Erreur lors de la synth√®se vocale: {e}")
        return None
#############################################################################
def speech_to_text():
    """Reconnaissance vocale via l'enregistrement audio (Streamlit + Whisper)"""
    st.info("üé§ Enregistrez votre r√©ponse vocale")
    audio_input = st.audio_input("Cliquez pour d√©marrer l'enregistrement")
    if audio_input:
        #st.audio(audio_input, format="audio/wav")
        # Sauvegarde temporaire du fichier audio
        tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        tmp_file.write(audio_input.getvalue())
        tmp_file.flush()
        tmp_path = tmp_file.name
    try:
            with open(tmp_path, "rb") as file:
                transcription = client.audio.transcriptions.create(
                    file=(tmp_path, file.read()),
                    model="whisper-large-v3-turbo",
                    response_format="verbose_json",
                    language="fr"
                )
                # Nettoyer le fichier temporaire
                os.unlink(tmp_path)
                st.session_state.audio_data = None
                st.rerun()
              
                # Effacer l'audio du widget pour permettre un nouvel enregistrement
                st.session_state.pop("audio_input", None)
            return transcription.text or "Aucune parole d√©tect√©e. Veuillez r√©essayer."
    except Exception as e:
            return f"Erreur lors de la transcription: {e}"

        
# ------------------------------------------------------------
# INTERFACE UTILISATEUR AM√âLIOR√âE
# ------------------------------------------------------------
def main():
    st.set_page_config(page_title="ü§ñ Assistant d'Entretien Intelligent", layout="wide")
    st.title("ü§ñ Assistant d'Entretien Intelligent")
    
    # Initialisation session
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "agent" not in st.session_state:
        st.session_state.agent = RecruitingAgent()
    
    if "waiting_for_response" not in st.session_state:
        st.session_state.waiting_for_response = False
    
    # Sidebar avec configuration
    with st.sidebar:
        st.header("üì§ Configuration de l'entretien")
        cv_file = st.file_uploader("T√©l√©versez votre CV (PDF)", type="pdf")
        job_desc = st.text_area("Description du poste", height=150,
                              placeholder="Copiez-collez l'offre d'emploi compl√®te")
        
        if st.button("üîç Analyser et d√©marrer", type="primary"):
            if cv_file and job_desc:
                with st.spinner("Analyse approfondie en cours..."):
                    st.session_state.agent.initialize_interview(cv_file, job_desc)
                    st.session_state.waiting_for_response = True
                    
                # Affichage du r√©sum√©
                st.success("Analyse termin√©e!")
                summary = st.session_state.agent.job_summary
                st.subheader("üìã Fiche de poste")
                st.json({
                    "Poste": summary["titre"],
                    "Comp√©tences": summary["competences_techniques"],
                    "Qualit√©s": summary["qualites_comportementales"],
                    "Niveau": summary["niveau_experience"]
                })
                
                st.rerun()
            else:
                st.error("Veuillez fournir CV et description de poste")
    
    # Zone principale de conversation
    if st.session_state.agent.phase == "interview":
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.header("üí¨ Entretien en cours")
            st.caption(f"Question {st.session_state.agent.question_count}/{st.session_state.agent.max_questions}")
            
            # Affichage messages
            for msg in st.session_state.messages:
                avatar = "ü§ñ" if msg["role"] == "assistant" else "üë§"
                with st.chat_message(msg["role"], avatar=avatar):
                    st.write(msg["content"])
                    if msg["role"] == "assistant":
                        audio_file = text_to_speech(msg["content"])
                        if audio_file:
                            st.audio(audio_file)

        with col2:
            st.subheader("üìä Progression")
            st.progress(st.session_state.agent.question_count / st.session_state.agent.max_questions)
            st.caption(f"{st.session_state.agent.question_count} questions pos√©es sur {st.session_state.agent.max_questions}")
            
            st.subheader("üìä Profil candidat")
            if st.session_state.agent.candidate_profile:
                profile = st.session_state.agent.candidate_profile
                st.metric("Comp√©tences identifi√©es", len(profile['competences_identifiees']))
                st.metric("Exp√©riences cl√©s", len(profile['experiences_cles']))
                
                with st.expander("D√©tails du profil"):
                    st.json(profile)
            
            st.subheader("üéØ Mode r√©ponse")
            input_mode = st.radio("Choisissez:", ["üé§ Vocal", "üìù Texte"], index=1)

        # Gestion des r√©ponses
        if st.session_state.waiting_for_response:
            user_input = None
            
            if input_mode == "üé§ Vocal":
                #if st.button("‚è∫Ô∏è D√©marrer l'enregistrement", type="secondary"):
                    with st.spinner("Enregistrement en cours..."):
                        user_input = speech_to_text()
                        if user_input:
                            st.success("Transcription r√©ussie!")
                            st.write(f"**Vous avez dit :** {user_input}")
            else:
                user_input = st.chat_input("Tapez votre r√©ponse ici...")
            
            if user_input and not user_input.startswith("Erreur"):
                # V√©rifier si le candidat veut arr√™ter
                if st.session_state.agent.check_candidate_cannot_continue(user_input):
                    st.warning("Le candidat a demand√© d'arr√™ter l'entretien.")
                    st.session_state.agent.phase = "evaluation"
                    st.rerun()
                    return
                
                # Traitement de la r√©ponse
                st.session_state.agent.history.append(("candidat", user_input))
                st.session_state.messages.append({"role": "user", "content": user_input})
                st.session_state.waiting_for_response = False
                
                # G√©n√©ration question suivante
                with st.spinner("üîç Analyse et g√©n√©ration de la prochaine question..."):
                    evaluation = st.session_state.agent.evaluate_response(user_input)
                    question = st.session_state.agent.generate_contextual_question(user_input)
                    
                    # V√©rifier si c'est le message de remerciement final
                    if "merci beaucoup" in question.lower() or "√©valuation finale" in question.lower():
                        st.session_state.agent.add_system_message(question)
                        st.session_state.agent.phase = "evaluation"
                        st.rerun()
                    else:
                        st.session_state.agent.add_system_message(question)
                
                # Affichage feedback
                with st.expander("üìù Feedback imm√©diat", expanded=True):
                    st.info(evaluation)
                
                st.session_state.waiting_for_response = True
                st.rerun()

        # Bouton terminer
        if st.session_state.waiting_for_response:
            if st.button("‚úÖ Terminer l'entretien", type="primary"):
                st.session_state.agent.phase = "evaluation"
                st.rerun()

    # √âvaluation finale
    if st.session_state.agent.phase == "evaluation":
        st.header("üìä Rapport de Performance Final")
        
        with st.spinner("üìä G√©n√©ration du rapport d√©taill√©..."):
            evaluation = st.session_state.agent.evaluate_performance()
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            with st.expander("üìù Rapport Complet", expanded=True):
                st.markdown(evaluation)
        
        with col2:
            st.download_button(
                "üíæ Exporter le rapport",
                evaluation,
                file_name="rapport_entretien.md",
                mime="text/markdown"
            )
            
            if st.button("üîÑ Nouvel entretien"):
                st.session_state.clear()
                st.rerun()

if __name__ == "__main__":
    main()
