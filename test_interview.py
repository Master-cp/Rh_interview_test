import boto3
from pathlib import Path
import tempfile 
import streamlit as st
from groq import Groq
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.embeddings import HuggingFaceEmbeddings 
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from gtts import gTTS
from io import BytesIO
import speech_recognition as sr
import os
import time
import json
import numpy as np
from audiorecorder import audiorecorder


# Initialisation du client Polly
polly_client = boto3.client('polly',
                           aws_access_key_id=st.secrets["AWS_ACCESS_KEY_ID"],
                           aws_secret_access_key=st.secrets["AWS_SECRET_ACCESS_KEY"],
                           region_name='us-east-1')

# Configuration Groq
client = Groq(api_key=st.secrets["GROQ_API_KEY"])   

# ------------------------------------------------------------
# CLASSES ET FONCTIONS AMÃ‰LIORÃ‰ES
# ------------------------------------------------------------
class RecruitingAgent:
    def __init__(self):
        self.phase = "initial"
        self.history = []
        self.vector_db = None
        self.job_description = ""
        self.cv_text = ""
        self.evaluations = []
        self.job_summary = {}
        self.candidate_profile = {
            "competences_identifiees": [],
            "experiences_cles": [],
            "points_forts": [],
            "points_faibles": [],
            "motivations": []
        }
        self.question_count = 0
        self.max_questions = 6
        
    def analyze_job_description(self, job_desc):
        """Analyse et rÃ©sume la description de poste"""
        prompt = f"""
        [DESCRIPTION DE POSTE Ã€ ANALYSER]
        {job_desc}

        [INSTRUCTIONS]
        En tant qu'expert RH, analysez cette offre d'emploi et :
        1. Extrayez un titre concis (max 5 mots)
        2. Listez les 3 compÃ©tences techniques principales
        3. Listez les 3 qualitÃ©s comportementales clÃ©s
        4. Identifiez le niveau d'expÃ©rience requis
        5. Extrayez 2 indicateurs de performance clÃ©s
        6. RÃ©sumez en 2 phrases les responsabilitÃ©s principales

        Formattez la rÃ©ponse en JSON avec ces clÃ©s :
        - "titre"
        - "competences_techniques"
        - "qualites_comportementales"
        - "niveau_experience"
        - "indicateurs_performance"
        - "responsabilites_principales"
        """
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            response_format={"type": "json_object"}
        )
        
        self.job_summary = eval(response.choices[0].message.content)
        return self.job_summary
    
    def initialize_interview(self, cv_file, job_description):
        """Initialise l'entretien avec analyse prÃ©alable"""
        self.job_description = job_description
        self.job_summary = self.analyze_job_description(job_description)
        
        # Traitement des documents
        self.cv_text, self.vector_db = self.process_documents(cv_file, job_description)
        self.phase = "interview"
        self.question_count = 0
        
        # Message d'introduction personnalisÃ©
        intro_message = (
            f"**Entretien pour le poste : {self.job_summary['titre']}**\n\n"
            f"**CompÃ©tences recherchÃ©es :** {', '.join(self.job_summary['competences_techniques'])}\n"
            f"**Profil attendu :** {self.job_summary['niveau_experience']} avec {', '.join(self.job_summary['qualites_comportementales'])}\n\n"
            "CommenÃ§ons par votre prÃ©sentation. Pourriez-vous vous dÃ©crire en 2 minutes "
            "en mettant l'accent sur votre adÃ©quation avec ce poste ?"
        )
        
        self.add_system_message(intro_message)
        self.question_count += 1
        
    def process_documents(self, cv_file, job_desc):
        """Traite les documents et extrait les informations clÃ©s"""
        with tempfile.TemporaryDirectory() as temp_dir:
            cv_path = os.path.join(temp_dir, cv_file.name)
            with open(cv_path, "wb") as f:
                f.write(cv_file.getvalue())
            
            loader = PyPDFLoader(cv_path)
            cv_data = loader.load()
        
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=300)
        cv_full_text = ''.join([d.page_content for d in cv_data])
        combined_text = f"CV DU CANDIDAT:\n{cv_full_text}\n\nDESCRIPTION DE POSTE:\n{job_desc}"
        
        return cv_full_text, FAISS.from_texts(
            texts=text_splitter.split_text(combined_text),
            embedding=HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
        )

    def extract_candidate_insights(self, user_response):
        """Extrait des insights du candidat de sa rÃ©ponse"""
        prompt = f"""
        [RÃ‰PONSE DU CANDIDAT]
        {user_response}

        [INSTRUCTIONS]
        Extrayez les informations suivantes de la rÃ©ponse :
        1. CompÃ©tences techniques mentionnÃ©es
        2. ExpÃ©riences professionnelles significatives
        3. Points forts dÃ©montrÃ©s
        4. Points faibles potentiels
        5. Motivations exprimÃ©es

        RÃ©pondez en JSON avec ces clÃ©s :
        - "competences_identifiees": liste
        - "experiences_cles": liste
        - "points_forts": liste
        - "points_faibles": liste
        - "motivations": liste
        """
        
        try:
            response = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.4,
                response_format={"type": "json_object"}
            )
            
            insights = eval(response.choices[0].message.content)
            
            # Mise Ã  jour du profil candidat
            for key in self.candidate_profile.keys():
                if key in insights and insights[key]:
                    self.candidate_profile[key].extend(insights[key])
            
            return insights
            
        except Exception as e:
            print(f"Erreur extraction insights: {e}")
            return {}
    
    def check_candidate_cannot_continue(self, user_response):
        """VÃ©rifie si le candidat indique ne pas pouvoir suivre la rencontre"""
        stop_phrases = [
            "je ne peux pas continuer",
            "je ne peux pas suivre",
            "je souhaite arrÃªter",
            "stop l'entretien",
            "arrÃªter l'entretien",
            "terminer maintenant",
            "je prÃ©fÃ¨re arrÃªter",
            "je veux arrÃªter",
            "pas possible de continuer",
            "impossible de poursuivre"
        ]
        
        user_response_lower = user_response.lower()
        return any(phrase in user_response_lower for phrase in stop_phrases)
    
    def generate_contextual_question(self, user_response):
        """GÃ©nÃ¨re des questions contextuelles basÃ©es sur l'historique"""
        # VÃ©rifier si le maximum de questions est atteint
        if self.question_count >= self.max_questions:
            thank_you_message = (
                "Merci beaucoup pour vos rÃ©ponses. Nous avons maintenant suffisamment "
                "d'Ã©lÃ©ments pour Ã©valuer votre candidature. "
                "Passons Ã  l'Ã©valuation finale de votre profil."
            )
            return thank_you_message
        
        # Extraction des insights de la rÃ©ponse
        insights = self.extract_candidate_insights(user_response)
        
        prompt = f"""
        [CONTEXTE DE L'ENTRETIEN]

        POSTE RECHERCHÃ‰:
        - Titre: {self.job_summary['titre']}
        - CompÃ©tences techniques requises: {self.job_summary['competences_techniques']}
        - QualitÃ©s comportementales: {self.job_summary['qualites_comportementales']}
        - ResponsabilitÃ©s: {self.job_summary['responsabilites_principales']}

        PROFIL DU CANDIDAT (extrait des rÃ©ponses prÃ©cÃ©dentes):
        - CompÃ©tences identifiÃ©es: {self.candidate_profile['competences_identifiees'][-3:] if self.candidate_profile['competences_identifiees'] else 'Aucune identifiÃ©e'}
        - ExpÃ©riences clÃ©s: {self.candidate_profile['experiences_cles'][-2:] if self.candidate_profile['experiences_cles'] else 'Aucune mentionnÃ©e'}
        - Points forts: {self.candidate_profile['points_forts'][-2:] if self.candidate_profile['points_forts'] else 'Non spÃ©cifiÃ©s'}

        DERNIÃˆRE RÃ‰PONSE DU CANDIDAT:
        {user_response[:500]}

        HISTORIQUE DE L'ENTRETIEN (derniÃ¨res interactions):
        {str(self.history[-3:]) if len(self.history) > 3 else 'DÃ©but de conversation'}

        [INSTRUCTIONS]
        En tant que recruteur expert, posez UNE seule question qui:
        1. S'appuie sur la derniÃ¨re rÃ©ponse du candidat
        2. Explore les compÃ©tences requises pour le poste
        3. VÃ©rifie l'adÃ©quation avec les responsabilitÃ©s du poste
        4. Maximum 70 mots
        5. En franÃ§ais, naturel et conversationnel

        La question doit crÃ©er un continuum logique avec l'Ã©change prÃ©cÃ©dent.
        """
        
        messages = [
            {"role": "system", "content": "Vous Ãªtes un recruteur technique expert, posez des questions pertinentes et naturelles."},
            *[{"role": "assistant" if role == "system" else "user", "content": msg} 
              for role, msg in self.history[-4:]],  # Garder les 4 derniers Ã©changes
            {"role": "user", "content": prompt}
        ]
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            temperature=0.7,
            max_tokens=100
        )
        
        self.question_count += 1
        return response.choices[0].message.content.strip()
    
    def add_system_message(self, message):
        """Ajoute un message systÃ¨me avec historique"""
        self.history.append(("system", message))
        st.session_state.messages.append({
            "role": "assistant",
            "content": message
        })

    def evaluate_response(self, user_response):
        """Ã‰value la rÃ©ponse du candidat de maniÃ¨re contextuelle"""
        prompt = f"""
        [CONTEXTE D'Ã‰VALUATION]

        EXIGENCES DU POSTE:
        - CompÃ©tences: {self.job_summary['competences_techniques']}
        - QualitÃ©s: {self.job_summary['qualites_comportementales']}
        - Niveau: {self.job_summary['niveau_experience']}

        HISTORIQUE RÃ‰CENT:
        {str(self.history[-2:]) if len(self.history) >= 2 else 'PremiÃ¨re question'}

        RÃ‰PONSE Ã€ Ã‰VALUER:
        {user_response}

        [CRITÃˆRES D'Ã‰VALUATION]
        1. Pertinence (1-5) : AdÃ©quation avec la question posÃ©e
        2. DÃ©tail technique (1-5) : PrÃ©cision des informations
        3. AdÃ©quation poste (1-5) : Lien avec les exigences du poste
        4. Progression (1-5) : AmÃ©lioration par rapport aux rÃ©ponses prÃ©cÃ©dentes

        Fournissez un feedback constructif en 2-3 phrases maximum.
        """
        
        evaluation = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4
        ).choices[0].message.content
        
        self.evaluations.append({
            "reponse": user_response[:200],
            "evaluation": evaluation,
            "timestamp": time.time()
        })
        
        return evaluation

    def evaluate_performance(self):
        """GÃ©nÃ¨re un rapport final complet"""
        prompt = f"""
        [SYNTHÃˆSE FINALE]

        POSTE: {self.job_summary['titre']}
        COMPÃ‰TENCES REQUISES: {self.job_summary['competences_techniques']}

        PROFIL CANDIDAT IDENTIFIÃ‰:
        - CompÃ©tences: {self.candidate_profile['competences_identifiees']}
        - ExpÃ©riences: {self.candidate_profile['experiences_cles']}
        - Points forts: {self.candidate_profile['points_forts']}
        - Motivations: {self.candidate_profile['motivations']}

        HISTORIQUE COMPLET: {json.dumps(self.history, ensure_ascii=False)}
        Ã‰VALUATIONS: {json.dumps(self.evaluations, ensure_ascii=False)}

        [INSTRUCTIONS]
        RÃ©digez un rapport dÃ©taillÃ© en franÃ§ais avec:
        1. Score global sur 10 avec justification
        2. Points forts alignÃ©s avec le poste
        3. Points d'amÃ©lioration critiques
        4. Recommandations concrÃ¨tes pour le candidat
        5. AdÃ©quation finale avec le poste (Fort/Moyen/Faible)

        Structurez avec des sections claires et soyez constructif.
        """
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        return response.choices[0].message.content

# ------------------------------------------------------------
# FONCTIONS AUDIO AMÃ‰LIORÃ‰ES
# ------------------------------------------------------------
def text_to_speech(text):
    """SynthÃ¨se vocale avec AWS Polly TTS (voix franÃ§aise)"""
    try:
        # CrÃ©ation d'un fichier temporaire pour l'audio
        speech_file_path = Path(tempfile.gettempdir()) / "speech.mp3"
        
        # Appel AWS Polly API TTS
        response = polly_client.synthesize_speech(
            Engine='generative',
            OutputFormat='mp3',
            Text=text,
            VoiceId='Liam',
            TextType='text'
        )
        
        # Sauvegarde du fichier audio
        if 'AudioStream' in response:
            with open(speech_file_path, 'wb') as file:
                file.write(response['AudioStream'].read())
        
        return str(speech_file_path)
        
    except Exception as e:
        print(f"Erreur lors de la synthÃ¨se vocale: {e}")
        return None

def speech_to_text():
    """Reconnaissance vocale via l'enregistrement audio"""
    st.info("ğŸ¤ Enregistrez votre rÃ©ponse vocale")
    # Utilisation de audiorecorder pour l'enregistrement vocal
    audio = audiorecorder(
                          start_prompt="Start recording",
                          stop_prompt="Stop recording",
                          pause_prompt="",
                          custom_style={'color': 'black'},
                          start_style={},
                          pause_style={},
                          stop_style={},
                          show_visualizer=True,
                          key=None)
     # Afficher l'audio enregistrÃ©
     st.audio(audio.export().read())
    if audio is not None and len(audio) > 0:
        try:
            # Sauvegarder temporairement les donnÃ©es audio
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                audio.export(tmp_file.name, format="wav")
                tmp_path = tmp_file.name

           

            # Transcription avec Whisper
            with open(tmp_path, "rb") as file:
                transcription = client.audio.transcriptions.create(
                    file=(tmp_path, file.read()),
                    model="whisper-large-v3-turbo",
                    response_format="text",
                    language="fr"
                )

            # Nettoyage du fichier temporaire
            os.unlink(tmp_path)

            if transcription.strip():
                return transcription
            else:
                return "Aucune parole dÃ©tectÃ©e. Veuillez rÃ©essayer."

        except Exception as e:
            return f"Erreur lors de la transcription: {str(e)}"

    return "En attente d'un enregistrement audio..."
# ------------------------------------------------------------
# INTERFACE UTILISATEUR AMÃ‰LIORÃ‰E
# ------------------------------------------------------------
def main():
    st.set_page_config(page_title="ğŸ¤– Assistant d'Entretien Intelligent", layout="wide")
    st.title("ğŸ¤– Assistant d'Entretien Intelligent")
    
    # Initialisation session
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "agent" not in st.session_state:
        st.session_state.agent = RecruitingAgent()
    
    if "waiting_for_response" not in st.session_state:
        st.session_state.waiting_for_response = False
    
    # Sidebar avec configuration
    with st.sidebar:
        st.header("ğŸ“¤ Configuration de l'entretien")
        cv_file = st.file_uploader("TÃ©lÃ©versez votre CV (PDF)", type="pdf")
        job_desc = st.text_area("Description du poste", height=150,
                              placeholder="Copiez-collez l'offre d'emploi complÃ¨te")
        
        if st.button("ğŸ” Analyser et dÃ©marrer", type="primary"):
            if cv_file and job_desc:
                with st.spinner("Analyse approfondie en cours..."):
                    st.session_state.agent.initialize_interview(cv_file, job_desc)
                    st.session_state.waiting_for_response = True
                    
                # Affichage du rÃ©sumÃ©
                st.success("Analyse terminÃ©e!")
                summary = st.session_state.agent.job_summary
                st.subheader("ğŸ“‹ Fiche de poste")
                st.json({
                    "Poste": summary["titre"],
                    "CompÃ©tences": summary["competences_techniques"],
                    "QualitÃ©s": summary["qualites_comportementales"],
                    "Niveau": summary["niveau_experience"]
                })
                
                st.rerun()
            else:
                st.error("Veuillez fournir CV et description de poste")
    
    # Zone principale de conversation
    if st.session_state.agent.phase == "interview":
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.header("ğŸ’¬ Entretien en cours")
            st.caption(f"Question {st.session_state.agent.question_count}/{st.session_state.agent.max_questions}")
            
            # Affichage messages
            for msg in st.session_state.messages:
                avatar = "ğŸ¤–" if msg["role"] == "assistant" else "ğŸ‘¤"
                with st.chat_message(msg["role"], avatar=avatar):
                    st.write(msg["content"])
                    if msg["role"] == "assistant":
                        audio_file = text_to_speech(msg["content"])
                        if audio_file:
                            st.audio(audio_file)

        with col2:
            st.subheader("ğŸ“Š Progression")
            st.progress(st.session_state.agent.question_count / st.session_state.agent.max_questions)
            st.caption(f"{st.session_state.agent.question_count} questions posÃ©es sur {st.session_state.agent.max_questions}")
            
            st.subheader("ğŸ“Š Profil candidat")
            if st.session_state.agent.candidate_profile:
                profile = st.session_state.agent.candidate_profile
                st.metric("CompÃ©tences identifiÃ©es", len(profile['competences_identifiees']))
                st.metric("ExpÃ©riences clÃ©s", len(profile['experiences_cles']))
                
                with st.expander("DÃ©tails du profil"):
                    st.json(profile)
            
            st.subheader("ğŸ¯ Mode rÃ©ponse")
            input_mode = st.radio("Choisissez:", ["ğŸ¤ Vocal", "ğŸ“ Texte"], index=1)

        # Gestion des rÃ©ponses
        if st.session_state.waiting_for_response:
            user_input = None
            
            if input_mode == "ğŸ¤ Vocal":
                #if st.button("âºï¸ DÃ©marrer l'enregistrement", type="secondary"):
                    with st.spinner("Enregistrement en cours..."):
                        user_input = speech_to_text()
                        if user_input:
                            st.success("Transcription rÃ©ussie!")
                            st.write(f"**Vous avez dit :** {user_input}")
            else:
                user_input = st.chat_input("Tapez votre rÃ©ponse ici...")
            
            if user_input and not user_input.startswith("Erreur"):
                # VÃ©rifier si le candidat veut arrÃªter
                if st.session_state.agent.check_candidate_cannot_continue(user_input):
                    st.warning("Le candidat a demandÃ© d'arrÃªter l'entretien.")
                    st.session_state.agent.phase = "evaluation"
                    st.rerun()
                    return
                
                # Traitement de la rÃ©ponse
                st.session_state.agent.history.append(("candidat", user_input))
                st.session_state.messages.append({"role": "user", "content": user_input})
                st.session_state.waiting_for_response = False
                
                # GÃ©nÃ©ration question suivante
                with st.spinner("ğŸ” Analyse et gÃ©nÃ©ration de la prochaine question..."):
                    evaluation = st.session_state.agent.evaluate_response(user_input)
                    question = st.session_state.agent.generate_contextual_question(user_input)
                    
                    # VÃ©rifier si c'est le message de remerciement final
                    if "merci beaucoup" in question.lower() or "Ã©valuation finale" in question.lower():
                        st.session_state.agent.add_system_message(question)
                        st.session_state.agent.phase = "evaluation"
                        st.rerun()
                    else:
                        st.session_state.agent.add_system_message(question)
                
                # Affichage feedback
                with st.expander("ğŸ“ Feedback immÃ©diat", expanded=True):
                    st.info(evaluation)
                
                st.session_state.waiting_for_response = True
                st.rerun()

        # Bouton terminer
        if st.session_state.waiting_for_response:
            if st.button("âœ… Terminer l'entretien", type="primary"):
                st.session_state.agent.phase = "evaluation"
                st.rerun()

    # Ã‰valuation finale
    if st.session_state.agent.phase == "evaluation":
        st.header("ğŸ“Š Rapport de Performance Final")
        
        with st.spinner("ğŸ“Š GÃ©nÃ©ration du rapport dÃ©taillÃ©..."):
            evaluation = st.session_state.agent.evaluate_performance()
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            with st.expander("ğŸ“ Rapport Complet", expanded=True):
                st.markdown(evaluation)
        
        with col2:
            st.download_button(
                "ğŸ’¾ Exporter le rapport",
                evaluation,
                file_name="rapport_entretien.md",
                mime="text/markdown"
            )
            
            if st.button("ğŸ”„ Nouvel entretien"):
                st.session_state.clear()
                st.rerun()

if __name__ == "__main__":
    main()
