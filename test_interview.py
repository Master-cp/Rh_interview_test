import boto3
from pathlib import Path
import tempfile 
import streamlit as st
from groq import Groq
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.embeddings import HuggingFaceEmbeddings 
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from gtts import gTTS
from io import BytesIO
import os
import time
import json
import numpy as np

# Initialisation du client Polly
polly_client = boto3.client('polly',
                           aws_access_key_id=st.secrets["AWS_ACCESS_KEY_ID"],
                           aws_secret_access_key=st.secrets["AWS_SECRET_ACCESS_KEY"],
                           region_name='us-east-1')

# Configuration Groq
client = Groq(api_key=st.secrets["GROQ_API_KEY"])   

# ------------------------------------------------------------
# CLASSES ET FONCTIONS AM√âLIOR√âES
# ------------------------------------------------------------
class RecruitingAgent:
    def __init__(self):
        self.phase = "initial"
        self.history = []
        self.vector_db = None
        self.job_description = ""
        self.cv_text = ""
        self.evaluations = []
        self.job_summary = {}
        self.matching_analysis = {}
        self.candidate_profile = {
            "competences_identifiees": [],
            "experiences_cles": [],
            "points_forts": [],
            "points_faibles": [],
            "motivations": []
        }
        self.question_count = 0
        self.max_questions = 6
        
    def analyze_job_description(self, job_desc):
        """Analyse et r√©sume la description de poste"""
        prompt = f"""
        [DESCRIPTION DE POSTE √Ä ANALYSER]
        {job_desc}

        [INSTRUCTIONS]
        En tant qu'expert RH, analysez cette offre d'emploi et :
        1. Extrayez un titre concis (max 5 mots)
        2. Listez les 3 comp√©tences techniques principales
        3. Listez les 3 qualit√©s comportementales cl√©s
        4. Identifiez le niveau d'exp√©rience requis
        5. Extrayez 2 indicateurs de performance cl√©s
        6. R√©sumez en 2 phrases les responsabilit√©s principales

        Formattez la r√©ponse en JSON avec ces cl√©s :
        - "titre"
        - "competences_techniques"
        - "qualites_comportementales"
        - "niveau_experience"
        - "indicateurs_performance"
        - "responsabilites_principales"
        """
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            response_format={"type": "json_object"}
        )
        
        self.job_summary = eval(response.choices[0].message.content)
        return self.job_summary
    
    def analyze_candidate_profile(self, cv_text, job_description):
        """Analyse le matching entre le candidat et le poste"""
        prompt = f"""
        [PROFIL DU CANDIDAT - CV]
        {cv_text[:3000]}
        
        [DESCRIPTION DU POSTE]
        {job_description}
        
        [INSTRUCTIONS]
        En tant qu'expert RH, analysez la correspondance entre le candidat et le poste :
        
        1. Points forts d'ad√©quation (comp√©tences correspondantes)
        2. Points d'√©cart (comp√©tences manquantes)
        3. Potentiel de d√©veloppement
        4. Recommandations pour l'entretien
        5. Score d'ad√©quation sur 100
        
        Formattez la r√©ponse en JSON avec ces cl√©s :
        - "points_forts_ad√©quation": liste des comp√©tences correspondantes
        - "points_ecart": liste des comp√©tences manquantes
        - "potentiel_developpement": analyse du potentiel
        - "recommandations_entretien": suggestions pour orienter l'entretien
        - "score_ad√©quation": score sur 100
        """
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            response_format={"type": "json_object"}
        )
        
        self.matching_analysis = eval(response.choices[0].message.content)
        return self.matching_analysis
    
    def initialize_interview(self, cv_file, job_description):
        """Initialise l'entretien avec analyse pr√©alable compl√®te"""
        self.job_description = job_description
        
        # Traitement des documents
        self.cv_text, self.vector_db = self.process_documents(cv_file, job_description)
        
        # Analyses en parall√®le
        self.job_summary = self.analyze_job_description(job_description)
        self.matching_analysis = self.analyze_candidate_profile(self.cv_text, job_description)
        
        self.phase = "interview"
        self.question_count = 0
        
        # Message d'introduction personnalis√© avec analyse
        intro_message = (
            f"**Entretien pour le poste : {self.job_summary['titre']}**\n\n"
            f"**üìä Score de correspondance : {self.matching_analysis['score_ad√©quation']}/100**\n\n"
            f"**‚úÖ Points forts d'ad√©quation :**\n"
            f"{chr(10).join(['‚Ä¢ ' + point for point in self.matching_analysis['points_forts_ad√©quation'][:3]])}\n\n"
            f"**üéØ Objectifs de l'entretien :**\n"
            f"{chr(10).join(['‚Ä¢ ' + reco for reco in self.matching_analysis['recommandations_entretien'][:2]])}\n\n"
            "**üí¨ Commen√ßons par votre pr√©sentation :**\n"
            "Pourriez-vous vous d√©crire en 2 minutes en mettant l'accent sur "
            "votre exp√©rience la plus pertinente pour ce poste ?"
        )
        
        self.add_system_message(intro_message)
        self.question_count += 1
        
    def process_documents(self, cv_file, job_desc):
        """Traite les documents et extrait les informations cl√©s"""
        with tempfile.TemporaryDirectory() as temp_dir:
            cv_path = os.path.join(temp_dir, cv_file.name)
            with open(cv_path, "wb") as f:
                f.write(cv_file.getvalue())
            
            loader = PyPDFLoader(cv_path)
            cv_data = loader.load()
        
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=300)
        cv_full_text = ''.join([d.page_content for d in cv_data])
        combined_text = f"CV DU CANDIDAT:\n{cv_full_text}\n\nDESCRIPTION DE POSTE:\n{job_desc}"
        
        return cv_full_text, FAISS.from_texts(
            texts=text_splitter.split_text(combined_text),
            embedding=HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
        )

    def extract_candidate_insights(self, user_response):
        """Extrait des insights du candidat de sa r√©ponse"""
        prompt = f"""
        [R√âPONSE DU CANDIDAT]
        {user_response}

        [INSTRUCTIONS]
        Extrayez les informations suivantes de la r√©ponse :
        1. Comp√©tences techniques mentionn√©es
        2. Exp√©riences professionnelles significatives
        3. Points forts d√©montr√©s
        4. Points faibles potentiels
        5. Motivations exprim√©es

        R√©pondez en JSON avec ces cl√©s :
        - "competences_identifiees": liste
        - "experiences_cles": liste
        - "points_forts": liste
        - "points_faibles": liste
        - "motivations": liste
        """
        
        try:
            response = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.4,
                response_format={"type": "json_object"}
            )
            
            insights = eval(response.choices[0].message.content)
            
            # Mise √† jour du profil candidat
            for key in self.candidate_profile.keys():
                if key in insights and insights[key]:
                    self.candidate_profile[key].extend(insights[key])
            
            return insights
            
        except Exception as e:
            print(f"Erreur extraction insights: {e}")
            return {}
    
    def check_candidate_cannot_continue(self, user_response):
        """V√©rifie si le candidat indique ne pas pouvoir suivre la rencontre"""
        stop_phrases = [
            "je ne peux pas continuer",
            "je ne peux pas suivre",
            "je souhaite arr√™ter",
            "stop l'entretien",
            "arr√™ter l'entretien",
            "terminer maintenant",
            "je pr√©f√®re arr√™ter",
            "je veux arr√™ter",
            "pas possible de continuer",
            "impossible de poursuivre"
        ]
        
        user_response_lower = user_response.lower()
        return any(phrase in user_response_lower for phrase in stop_phrases)
    
    def generate_contextual_question(self, user_response):
        """G√©n√®re des questions contextuelles bas√©es sur l'historique"""
        # V√©rifier si le maximum de questions est atteint
        if self.question_count >= self.max_questions:
            thank_you_message = (
                "Merci beaucoup pour vos r√©ponses. Nous avons maintenant suffisamment "
                "d'√©l√©ments pour √©valuer votre candidature. "
                "Passons √† l'√©valuation finale de votre profil."
            )
            return thank_you_message
        
        # Extraction des insights de la r√©ponse
        insights = self.extract_candidate_insights(user_response)
        
        prompt = f"""
        [CONTEXTE DE L'ENTRETIEN]

        POSTE RECHERCH√â:
        - Titre: {self.job_summary['titre']}
        - Comp√©tences techniques requises: {self.job_summary['competences_techniques']}
        - Qualit√©s comportementales: {self.job_summary['qualites_comportementales']}
        - Responsabilit√©s: {self.job_summary['responsabilites_principales']}

        PROFIL DU CANDIDAT (extrait des r√©ponses pr√©c√©dentes):
        - Comp√©tences identifi√©es: {self.candidate_profile['competences_identifiees'][-3:] if self.candidate_profile['competences_identifiees'] else 'Aucune identifi√©e'}
        - Exp√©riences cl√©s: {self.candidate_profile['experiences_cles'][-2:] if self.candidate_profile['experiences_cles'] else 'Aucune mentionn√©e'}
        - Points forts: {self.candidate_profile['points_forts'][-2:] if self.candidate_profile['points_forts'] else 'Non sp√©cifi√©s'}

        DERNI√àRE R√âPONSE DU CANDIDAT:
        {user_response[:500]}

        HISTORIQUE DE L'ENTRETIEN (derni√®res interactions):
        {str(self.history[-3:]) if len(self.history) > 3 else 'D√©but de conversation'}

        [INSTRUCTIONS]
        En tant que recruteur expert, posez UNE seule question qui:
        1. S'appuie sur la derni√®re r√©ponse du candidat
        2. Explore les comp√©tences requises pour le poste
        3. V√©rifie l'ad√©quation avec les responsabilit√©s du poste
        4. Maximum 70 mots
        5. En fran√ßais, naturel et conversationnel

        La question doit cr√©er un continuum logique avec l'√©change pr√©c√©dent.
        """
        
        messages = [
            {"role": "system", "content": "Vous √™tes un recruteur technique expert, posez des questions pertinentes et naturelles."},
            *[{"role": "assistant" if role == "system" else "user", "content": msg} 
              for role, msg in self.history[-4:]],  # Garder les 4 derniers √©changes
            {"role": "user", "content": prompt}
        ]
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            temperature=0.7,
            max_tokens=100
        )
        
        self.question_count += 1
        return response.choices[0].message.content.strip()
    
    def add_system_message(self, message):
        """Ajoute un message syst√®me avec historique"""
        self.history.append(("system", message))
        st.session_state.messages.append({
            "role": "assistant",
            "content": message
        })

    def evaluate_response(self, user_response):
        """√âvalue la r√©ponse du candidat de mani√®re contextuelle"""
        prompt = f"""
        [CONTEXTE D'√âVALUATION]

        EXIGENCES DU POSTE:
        - Comp√©tences: {self.job_summary['competences_techniques']}
        - Qualit√©s: {self.job_summary['qualites_comportementales']}
        - Niveau: {self.job_summary['niveau_experience']}

        HISTORIQUE R√âCENT:
        {str(self.history[-2:]) if len(self.history) >= 2 else 'Premi√®re question'}

        R√âPONSE √Ä √âVALUER:
        {user_response}

        [CRIT√àRES D'√âVALUATION]
        1. Pertinence (1-5) : Ad√©quation avec la question pos√©e
        2. D√©tail technique (1-5) : Pr√©cision des informations
        3. Ad√©quation poste (1-5) : Lien avec les exigences du poste
        4. Progression (1-5) : Am√©lioration par rapport aux r√©ponses pr√©c√©dentes

        Fournissez un feedback constructif en 2-3 phrases maximum.
        """
        
        evaluation = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4
        ).choices[0].message.content
        
        self.evaluations.append({
            "reponse": user_response[:200],
            "evaluation": evaluation,
            "timestamp": time.time()
        })
        
        return evaluation

    def evaluate_performance(self):
        """G√©n√®re un rapport final complet"""
        prompt = f"""
        [SYNTH√àSE FINALE]

        POSTE: {self.job_summary['titre']}
        COMP√âTENCES REQUISES: {self.job_summary['competences_techniques']}

        PROFIL CANDIDAT IDENTIFI√â:
        - Comp√©tences: {self.candidate_profile['competences_identifiees']}
        - Exp√©riences: {self.candidate_profile['experiences_cles']}
        - Points forts: {self.candidate_profile['points_forts']}
        - Motivations: {self.candidate_profile['motivations']}

        ANALYSE DE MATCHING INITIALE:
        - Score: {self.matching_analysis['score_ad√©quation']}/100
        - Points forts: {self.matching_analysis['points_forts_ad√©quation']}
        - Points d'√©cart: {self.matching_analysis['points_ecart']}

        HISTORIQUE COMPLET: {json.dumps(self.history, ensure_ascii=False)}
        √âVALUATIONS: {json.dumps(self.evaluations, ensure_ascii=False)}

        [INSTRUCTIONS]
        R√©digez un rapport d√©taill√© en fran√ßais avec:
        1. Score global sur 10 avec justification
        2. Points forts align√©s avec le poste
        3. Points d'am√©lioration critiques
        4. Recommandations concr√®tes pour le candidat
        5. Ad√©quation finale avec le poste (Fort/Moyen/Faible)
        6. Comparaison avec l'analyse initiale

        Structurez avec des sections claires et soyez constructif.
        """
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        return response.choices[0].message.content

# ------------------------------------------------------------
# FONCTIONS AUDIO AM√âLIOR√âES
# ------------------------------------------------------------
def text_to_speech(text):
    """Synth√®se vocale avec AWS Polly TTS (voix fran√ßaise)"""
    try:
        # Cr√©ation d'un fichier temporaire pour l'audio
        speech_file_path = Path(tempfile.gettempdir()) / "speech.mp3"
        
        # Appel AWS Polly API TTS
        response = polly_client.synthesize_speech(
            Engine='neural',
            OutputFormat='mp3',
            Text=text,
            VoiceId='Lea',
            TextType='text'
        )
        
        # Sauvegarde du fichier audio
        if 'AudioStream' in response:
            with open(speech_file_path, 'wb') as file:
                file.write(response['AudioStream'].read())
        
        return str(speech_file_path)
        
    except Exception as e:
        print(f"Erreur lors de la synth√®se vocale: {e}")
        return None

def speech_to_text():
    """Reconnaissance vocale via l'audio input de Streamlit"""
    st.info("üé§ Enregistrez votre r√©ponse (5 secondes maximum)")
    
    # Utilisation de st.audio_input
    audio_data = st.audio_input(
        "Parlez maintenant:",
        key="audio_recorder",
        help="Cliquez pour enregistrer votre r√©ponse vocale (5s max)"
    )
    
    if audio_data is not None:
        try:
            # V√©rifier la taille du fichier audio (√©viter les fichiers vides)
            if len(audio_data.getvalue()) < 1000:  # Moins de 1KB = probablement vide
                return "Audio trop court. Veuillez r√©essayer."
            
            # Sauvegarder temporairement
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                tmp_file.write(audio_data.getvalue())
                tmp_path = tmp_file.name
            
            # Transcription avec Whisper
            with open(tmp_path, "rb") as file:
                transcription = client.audio.transcriptions.create(
                    file=(tmp_path, file.read()),
                    model="whisper-large-v3-turbo",
                    response_format="text",
                    language="fr"
                )
            
            # Nettoyage
            os.unlink(tmp_path)
            
            if transcription and transcription.strip():
                return transcription
            else:
                return "Aucune parole d√©tect√©e. Veuillez r√©essayer."
            
        except Exception as e:
            return f"Erreur technique: {str(e)}"
    
    return None

# ------------------------------------------------------------
# INTERFACE UTILISATEUR AM√âLIOR√âE
# ------------------------------------------------------------
def main():
    st.set_page_config(page_title="ü§ñ Assistant d'Entretien Intelligent", layout="wide")
    st.title("ü§ñ Assistant d'Entretien Intelligent")
    
    # Initialisation session
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "agent" not in st.session_state:
        st.session_state.agent = RecruitingAgent()
    
    if "waiting_for_response" not in st.session_state:
        st.session_state.waiting_for_response = False
    
    if "analysis_complete" not in st.session_state:
        st.session_state.analysis_complete = False
    
    # Sidebar avec configuration
    with st.sidebar:
        st.header("üì§ Configuration de l'entretien")
        cv_file = st.file_uploader("T√©l√©versez votre CV (PDF)", type="pdf", key="cv_uploader")
        job_desc = st.text_area("Description du poste", height=150,
                              placeholder="Copiez-collez l'offre d'emploi compl√®te",
                              key="job_desc_input")
        
        if st.button("üîç Analyser et d√©marrer", type="primary", key="start_analysis"):
            if cv_file and job_desc:
                # R√©initialiser l'√©tat pr√©c√©dent
                st.session_state.messages = []
                st.session_state.waiting_for_response = False
                st.session_state.analysis_complete = False
                
                # Analyse pr√©liminaire
                with st.spinner("üìä Analyse approfondie en cours..."):
                    try:
                        st.session_state.agent.initialize_interview(cv_file, job_desc)
                        st.session_state.analysis_complete = True
                        st.session_state.waiting_for_response = True
                        
                        st.success("‚úÖ Analyse termin√©e!")
                        
                    except Exception as e:
                        st.error(f"Erreur lors de l'analyse: {str(e)}")
                
                st.rerun()
            else:
                st.error("Veuillez fournir CV et description de poste")
        
        # Afficher l'analyse de matching si disponible
        if st.session_state.analysis_complete and hasattr(st.session_state.agent, 'matching_analysis'):
            st.write("---")
            st.subheader("üìã Analyse de correspondance")
            
            analysis = st.session_state.agent.matching_analysis
            st.metric("Score de correspondance", f"{analysis['score_ad√©quation']}/100")
            
            with st.expander("üìä D√©tails de l'analyse", expanded=False):
                st.write("**‚úÖ Points forts :**")
                for point in analysis['points_forts_ad√©quation'][:3]:
                    st.success(f"‚Ä¢ {point}")
                
                st.write("**‚ö†Ô∏è Points d'√©cart :**")
                for point in analysis['points_ecart'][:2]:
                    st.warning(f"‚Ä¢ {point}")
                
                st.write("**üí° Recommandations :**")
                for reco in analysis['recommandations_entretien'][:2]:
                    st.info(f"‚Ä¢ {reco}")
    
    # Zone principale
    if st.session_state.analysis_complete:
        # Afficher l'analyse de matching en haut de page
        analysis = st.session_state.agent.matching_analysis
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("üìä Score de correspondance", f"{analysis['score_ad√©quation']}/100")
        
        with col2:
            st.metric("‚úÖ Points forts", len(analysis['points_forts_ad√©quation']))
        
        with col3:
            st.metric("‚ö†Ô∏è Points d'√©cart", len(analysis['points_ecart']))
        
        # Interface d'entretien
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.header("üí¨ Entretien en cours")
            st.caption(f"Question {st.session_state.agent.question_count}/{st.session_state.agent.max_questions}")
            
            # Affichage messages
            for msg in st.session_state.messages:
                avatar = "ü§ñ" if msg["role"] == "assistant" else "üë§"
                with st.chat_message(msg["role"], avatar=avatar):
                    st.write(msg["content"])
                    if msg["role"] == "assistant":
                        audio_file = text_to_speech(msg["content"])
                        if audio_file:
                            st.audio(audio_file)

        with col2:
            st.subheader("üìä Progression")
            progress_value = st.session_state.agent.question_count / st.session_state.agent.max_questions
            st.progress(progress_value)
            st.caption(f"{st.session_state.agent.question_count} questions pos√©es sur {st.session_state.agent.max_questions}")
            
            st.subheader("üìä Profil candidat")
            if st.session_state.agent.candidate_profile:
                profile = st.session_state.agent.candidate_profile
                st.metric("Comp√©tences identifi√©es", len(profile['competences_identifiees']))
                st.metric("Exp√©riences cl√©s", len(profile['experiences_cles']))
                
                with st.expander("D√©tails du profil"):
                    st.json(profile)
            
            st.subheader("üéØ Mode r√©ponse")
            input_mode = st.radio("Choisissez:", ["üìù Texte", "üé§ Vocal"], index=0, key="input_mode")

        # Gestion des r√©ponses
        if st.session_state.waiting_for_response:
            st.write("---")
            st.subheader("üí¨ Votre r√©ponse")
            
            user_input = None
            
            if input_mode == "üé§ Vocal":
                st.info("üé§ Utilisez votre microphone pour r√©pondre")
                
                # Enregistrement audio
                audio_data = st.audio_input(
                    "Parlez maintenant:",
                    key="audio_recorder",
                    help="Cliquez pour enregistrer votre r√©ponse"
                )
                
                if audio_data:
                    with st.spinner("Transcription en cours..."):
                        user_input = speech_to_text()
                        if user_input and not user_input.startswith("Erreur"):
                            st.success("‚úÖ Transcription r√©ussie!")
                            st.write(f"**Transcription :** {user_input}")
            
            else:  # Mode Texte
                st.info("üìù Tapez votre r√©ponse ci-dessous")
                user_input = st.text_area(
                    "Votre r√©ponse:",
                    height=150,
                    key="text_response",
                    placeholder="√âcrivez votre r√©ponse ici..."
                )
            
            # Bouton de soumission
            if user_input and st.button("‚úÖ Soumettre la r√©ponse", type="primary", key="submit_response"):
                # V√©rifier si le candidat veut arr√™ter
                if st.session_state.agent.check_candidate_cannot_continue(user_input):
                    st.warning("Le candidat a demand√© d'arr√™ter l'entretien.")
                    st.session_state.agent.phase = "evaluation"
                    st.rerun()
                    return
                
                # Ajouter la r√©ponse du candidat √† l'historique
                st.session_state.agent.history.append(("candidat", user_input))
                st.session_state.messages.append({"role": "user", "content": user_input})
                
                # D√©sactiver l'attente de r√©ponse pendant le traitement
                st.session_state.waiting_for_response = False
                
                # G√©n√©ration question suivante
                with st.spinner("üîç Analyse de votre r√©ponse et g√©n√©ration de la prochaine question..."):
                    # √âvaluation de la r√©ponse
                    evaluation = st.session_state.agent.evaluate_response(user_input)
                    
                    # G√©n√©ration de la question suivante
                    question = st.session_state.agent.generate_contextual_question(user_input)
                    
                    # Ajouter la question √† l'historique
                    st.session_state.agent.add_system_message(question)
                    
                    # V√©rifier si c'est la fin de l'entretien
                    if "merci beaucoup" in question.lower() or "√©valuation finale" in question.lower():
                        st.session_state.agent.phase = "evaluation"
                
                # Afficher le feedback
                st.success("‚úÖ R√©ponse enregistr√©e avec succ√®s!")
                with st.expander("üìù Feedback imm√©diat", expanded=True):
                    st.info(evaluation)
                
                # R√©activer l'attente de r√©ponse pour la prochaine question
                st.session_state.waiting_for_response = True
                
                # Forcer le rerun pour afficher la nouvelle question
                st.rerun()

        # Bouton pour terminer l'entretien manuellement
        if st.session_state.waiting_for_response:
            if st.button("‚úÖ Terminer l'entretien", type="primary", key="end_interview"):
                st.session_state.agent.phase = "evaluation"
                st.rerun()

    # √âvaluation finale
    elif st.session_state.agent.phase == "evaluation":
        st.header("üìä Rapport de Performance Final")
        
        with st.spinner("üìä G√©n√©ration du rapport d√©taill√©..."):
            evaluation = st.session_state.agent.evaluate_performance()
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            with st.expander("üìù Rapport Complet", expanded=True):
                st.markdown(evaluation)
        
        with col2:
            st.download_button(
                "üíæ Exporter le rapport",
                evaluation,
                file_name="rapport_entretien.md",
                mime="text/markdown",
                key="download_report"
            )
            
            if st.button("üîÑ Nouvel entretien", key="new_interview"):
                # R√©initialisation compl√®te
                for key in list(st.session_state.keys()):
                    del st.session_state[key]
                st.rerun()
    
    # √âtat initial - avant le d√©marrage de l'entretien
    else:
        st.info("üëã Bienvenue! Veuillez configurer l'entretien dans la sidebar √† gauche.")
        st.write("""
        ### Instructions :
        1. üì§ T√©l√©versez votre CV en format PDF
        2. üìù Collez la description du poste
        3. üîç Cliquez sur \"Analyser et d√©marrer\"
        4. üé§ R√©pondez aux questions avec votre voix ou par texte
        """)
        
        # Section d√©mo
        with st.expander("‚ÑπÔ∏è Comment √ßa fonctionne", expanded=False):
            st.write("""
            **L'assistant va :**
            1. Analyser votre CV et l'offre d'emploi
            2. √âvaluer la correspondance entre votre profil et le poste
            3. G√©n√©rer des questions personnalis√©es
            4. Fournir un feedback apr√®s chaque r√©ponse
            5. Produire un rapport d√©taill√© √† la fin
            """)

if __name__ == "__main__":
    main()
